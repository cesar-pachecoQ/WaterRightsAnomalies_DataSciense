{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5dbe9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coloque su dedo en el lector de huellas dactilares\n",
      "La huella no coincide\n",
      "Coloque su dedo en el lector de huellas dactilares\n",
      "vm.drop_caches = 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def clear_memory():\n",
    "    !sudo sysctl -w vm.drop_caches=3\n",
    "clear_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea7199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import ManipulateData\n",
    "import MetodoLexico\n",
    "import DataLoader_Polars\n",
    "from rapidfuzz import fuzz\n",
    "import jellyfish\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d1259ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader_Polars.DataLoaderPolars(\"../DataSets_CSVs/DataSets_Parquets/\")\n",
    "df_concesiones = data_loader.load_concesiones()\n",
    "manipulator = ManipulateData.ManipulateData(df_concesiones, \"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ba0d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Para buscar cuales pueden ser las metricas y metodos lexicos correctos a utilizar hacemos una extracción de los titulares únicos a los que nos enfrentamos\\ntitulares_unicos = df_concesiones.sort('titular').select('titular').unique()\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Para buscar cuales pueden ser las metricas y metodos lexicos correctos a utilizar hacemos una extracción de los titulares únicos a los que nos enfrentamos\n",
    "titulares_unicos = df_concesiones.sort('titular').select('titular').unique()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769aa9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concesiones = manipulator.date_string_to_date(df_concesiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b786a159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para truncar fechas que ya tienen tiempo\n",
    "df_concesiones = df_concesiones.with_columns(\n",
    "    pl.col('ultimo_registro').dt.date().alias('ultimo_registro')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76889004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_nombres_titulares_antes_estandarizar = len(df_concesiones.select('titular').unique())\n",
    "#n_nombres_titulares_antes_estandarizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07979f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#Para un segundo enfoque podemos normalizar los textos de los titulares con diferentes parámetros\\n\\ndf_concesiones = ManipulateData.ManipulateData(df_concesiones).estandarizar_titular('titular',\\n                                                                                    sin_espacios=False,\\n                                                                                    sin_stopword=True,\\n                                                                                    sin_terminos_mercantiles=True,\\n                                                                                    quitar_tokens_1_letra=True)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#Para un segundo enfoque podemos normalizar los textos de los titulares con diferentes parámetros\n",
    "\n",
    "df_concesiones = ManipulateData.ManipulateData(df_concesiones).estandarizar_titular('titular',\n",
    "                                                                                    sin_espacios=False,\n",
    "                                                                                    sin_stopword=True,\n",
    "                                                                                    sin_terminos_mercantiles=True,\n",
    "                                                                                    quitar_tokens_1_letra=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1961c3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_nombres_titulares_despues_estandarizar = len(df_concesiones.select('titular').unique())\n",
    "#n_nombres_titulares_despues_estandarizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5fd307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar columnas en el orden deseado\n",
    "\n",
    "df_concesiones = df_concesiones.select([\n",
    "    'titulo', 'titular', 'ultimo_registro',\n",
    "    *[col for col in df_concesiones.columns if col not in ['titulo', 'titular', 'ultimo_registro']]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b27b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar el DataFrame\n",
    "df_concesiones = df_concesiones.sort([\n",
    "    pl.col('titulo').count().over('titulo'),\n",
    "    'titular', \n",
    "    'ultimo_registro'\n",
    "], descending=[True, False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1026d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener información de títulos y titulares\n",
    "titulos_info = df_concesiones.group_by('titulo').agg([\n",
    "    pl.col('titular').n_unique().alias('N_titulares')\n",
    "]).sort('N_titulares', descending=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baf79837",
   "metadata": {},
   "outputs": [],
   "source": [
    "volumenes_totales_info = df_concesiones.group_by('titulo').agg([\n",
    "    pl.col('volumen_de_extraccion_anual_de_aguas_nacionales_que_ampara_el_titulo_en_m3').n_unique().alias('cambios_volumen'),\n",
    "    pl.col('volumen_de_extraccion_anual_de_aprovechamientos_subterraneos_en_m3').n_unique().alias('cambios_volumen_subterraneo'),\n",
    "    pl.col('volumen_de_extraccion_anual_de_aprovechamientos_superficiales_en_m3').n_unique().alias('cambios_volumen_superficial')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2843226",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodos_info = df_concesiones.group_by('titulo').agg([\n",
    "    pl.col('ultimo_registro').n_unique().alias('cantidad_periodos'),\n",
    "    pl.col('ultimo_registro').unique().alias('periodos_presentes'),\n",
    "    pl.col('ultimo_registro').count().alias('N_cambios_ultimo_registro'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c777704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Recrear df_anomalias con los datos\n",
    "df_anomalias = pl.DataFrame({\n",
    "    'titulo': titulos_info['titulo'].to_list(),\n",
    "    'N_titulares': titulos_info['N_titulares'].to_list(),\n",
    "    'Score': [None] * len(titulos_info),\n",
    "    'Diferente_titular': [None] * len(titulos_info),\n",
    "    'Caracteres_distintos': [None]* len(titulos_info),\n",
    "    'Cambios_en_20_periodos': periodos_info['N_cambios_ultimo_registro'].to_list(), # Cuantas veces aparece el registro en los 20 periodos\n",
    "    'Periodos': periodos_info['periodos_presentes'].to_list(), # aqui se ponen los periodos en los que hubieron cambios.\n",
    "    'Cantidad_periodos': periodos_info['cantidad_periodos'].to_list(), #Cuantos periodos hay en total en dicho registro\n",
    "    'Anomalia_V_Total': volumenes_totales_info['cambios_volumen'].to_list(),\n",
    "    'Anomalia_V_Subterraneo': volumenes_totales_info['cambios_volumen_subterraneo'].to_list(),\n",
    "    'Anomalia_V_Superficial': volumenes_totales_info['cambios_volumen_superficial'].to_list()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6643c453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef length_prefilter(a: str, b: str, base_abs: int = 5, rel_long: float = 0.50) -> bool:\\n    # Semántica: devuelve True si las longitudes son tan distintas\\n    # que podemos DESCARTAR el par sin seguir a métodos léxicos.\\n    L1 = len(a or \"\")\\n    L2 = len(b or \"\")\\n    Lmax = max(L1, L2)\\n    if Lmax <= 3:\\n        return False  # no decidas por longitud cuando son ultra cortos\\n\\n    # Umbral absoluto dinámico (20% de Lmax, al menos base_abs)\\n    abs_thr = max(base_abs, int(round(0.20 * Lmax)))\\n\\n    # Umbral relativo: más exigente en cortos\\n    rel_thr = 0.40 if Lmax < 10 else rel_long  # p.ej. 0.40 para cortos, 0.50 para largos\\n\\n    gap_abs = abs(L1 - L2)\\n    gap_rel = gap_abs / Lmax\\n\\n    return (gap_abs > abs_thr) and (gap_rel > rel_thr)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def length_prefilter(a: str, b: str, base_abs: int = 5, rel_long: float = 0.50) -> bool:\n",
    "    # Semántica: devuelve True si las longitudes son tan distintas\n",
    "    # que podemos DESCARTAR el par sin seguir a métodos léxicos.\n",
    "    L1 = len(a or \"\")\n",
    "    L2 = len(b or \"\")\n",
    "    Lmax = max(L1, L2)\n",
    "    if Lmax <= 3:\n",
    "        return False  # no decidas por longitud cuando son ultra cortos\n",
    "\n",
    "    # Umbral absoluto dinámico (20% de Lmax, al menos base_abs)\n",
    "    abs_thr = max(base_abs, int(round(0.20 * Lmax)))\n",
    "\n",
    "    # Umbral relativo: más exigente en cortos\n",
    "    rel_thr = 0.40 if Lmax < 10 else rel_long  # p.ej. 0.40 para cortos, 0.50 para largos\n",
    "\n",
    "    gap_abs = abs(L1 - L2)\n",
    "    gap_rel = gap_abs / Lmax\n",
    "\n",
    "    return (gap_abs > abs_thr) and (gap_rel > rel_thr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50492477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef score_y_clase(a:str, b:str):\\n    # Pre-filtrado por longitud\\n    if length_prefilter(a, b):\\n        return 0, 0\\n    else:\\n        #metricas\\n        ts = fuzz.token_set_ratio(a, b)\\n        jw = jellyfish.jaro_winkler_similarity(a, b) * 100\\n        score = (ts + jw) / 2\\n        #reglas    \\n        if ts >= 96 or (ts >= 93 and jw >= 93):\\n            clase = 1 #iguales\\n        elif ts < 90 or (ts < 85 and jw < 88):\\n            clase = 0 #diferentes\\n        else:\\n            clase = 2 \\n    return score, clase\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def score_y_clase(a:str, b:str):\n",
    "    # Pre-filtrado por longitud\n",
    "    if length_prefilter(a, b):\n",
    "        return 0, 0\n",
    "    else:\n",
    "        #metricas\n",
    "        ts = fuzz.token_set_ratio(a, b)\n",
    "        jw = jellyfish.jaro_winkler_similarity(a, b) * 100\n",
    "        score = (ts + jw) / 2\n",
    "        #reglas    \n",
    "        if ts >= 96 or (ts >= 93 and jw >= 93):\n",
    "            clase = 1 #iguales\n",
    "        elif ts < 90 or (ts < 85 and jw < 88):\n",
    "            clase = 0 #diferentes\n",
    "        else:\n",
    "            clase = 2 \n",
    "    return score, clase\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990c1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_y_clase_wrapper(a: str, b: str):\n",
    "    \"\"\"Wrapper para usar MetodoLexico en lugar de la función score_y_clase\"\"\"\n",
    "    metodo = MetodoLexico.MetodoLexico(a, b)\n",
    "    return metodo.score_y_clase()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "636dc646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_metrics(a: str, b: str):\n",
    "    \"\"\"Función que retorna todos los valores de una vez para evitar múltiples instanciaciones\"\"\"\n",
    "    metodo = MetodoLexico.MetodoLexico(a, b)\n",
    "    score, clase, caracteres_conflictivos = metodo.score_y_clase()\n",
    "    return (score, clase, caracteres_conflictivos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63644f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Títulos con exactamente 2 titulares únicos\n",
    "tit2 = (\n",
    "    df_concesiones\n",
    "    .select(['titulo','titular'])\n",
    "    .unique()\n",
    "    .group_by('titulo')\n",
    "    .agg(pl.col('titular').unique().alias('titulares'))\n",
    "    .with_columns(pl.col('titulares').list.len().alias('N_titulares'))\n",
    "    .filter(pl.col('N_titulares') == 2)\n",
    ")\n",
    "\n",
    "# Extrae pares (t1, t2)\n",
    "tit2_pairs = tit2.with_columns([\n",
    "    pl.col('titulares').list.get(0).alias('titular1'),\n",
    "    pl.col('titulares').list.get(1).alias('titular2')\n",
    "]).select(['titulo','titular1','titular2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9356d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5046/3898457111.py:8: MapWithoutReturnDtypeWarning: 'return_dtype' of function python_udf must be set\n",
      "\n",
      "A later expression might fail because the output type is not known. Set return_dtype=pl.self_dtype() if the type is unchanged, or set the proper output data type.\n",
      "  .with_columns([\n"
     ]
    }
   ],
   "source": [
    "tit2_scored = (\n",
    "    tit2_pairs.with_columns([\n",
    "        pl.struct(['titular1','titular2']).map_elements(\n",
    "            lambda s: get_all_metrics(s['titular1'], s['titular2']),\n",
    "            return_dtype=pl.Object  # <- importante si all_metrics es tuple/list\n",
    "        ).alias('all_metrics')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        pl.col('all_metrics').map_elements(lambda x: x[0]).alias('Score'),\n",
    "        pl.col('all_metrics').map_elements(lambda x: x[1]).alias('Diferente_titular'),\n",
    "        pl.col('all_metrics').map_elements(lambda x: x[2]).alias('Caracteres_distintos'),\n",
    "    ])\n",
    "    .drop('all_metrics')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58b1285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalias = (\n",
    "    df_anomalias.drop(['Score','Diferente_titular', 'Caracteres_distintos'])  # Eliminar las columnas anteriores\n",
    "    .join(tit2_scored.select(['titulo','Score','Diferente_titular','Caracteres_distintos']), on='titulo', how='left')  # Incluir Caracteres_distintos\n",
    "    .select([\n",
    "        'titulo',\n",
    "        'N_titulares',\n",
    "        'Score',\n",
    "        'Diferente_titular',\n",
    "        'Caracteres_distintos',\n",
    "        'Cambios_en_20_periodos',\n",
    "        'Periodos',\n",
    "        'Cantidad_periodos',\n",
    "        'Anomalia_V_Total',\n",
    "        'Anomalia_V_Subterraneo',\n",
    "        'Anomalia_V_Superficial'\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "647e3339",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fechas = df_concesiones.select('ultimo_registro').unique().sort('ultimo_registro')\n",
    "# titulos_list = df_concesiones.group_by('titulo').agg(pl.count()).sort('count', descending=True)\n",
    "# nombres_unicos_en_titulares = df_concesiones.sort('titular').select('titular').unique()\n",
    "# Distribución de títulos por frecuencia\n",
    "#dist_titulos_list = titulos_list.group_by('count').agg(pl.count().alias('frequency')).sort('count',descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18bef5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.bar(dist_titulos_list['count'].to_list(), dist_titulos_list['frequency'].to_list())\\nplt.yscale('log')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "plt.bar(dist_titulos_list['count'].to_list(), dist_titulos_list['frequency'].to_list())\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c77529",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e19fa80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subterraneas = data_loader.load_subterraneas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef0af935",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_superficiales = data_loader.load_superficiales()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21408eca",
   "metadata": {},
   "source": [
    "### Primero comparamos el numero de titulos de cada dataset y vemos que disntan entre si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fe0b01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TÍTULOS ÚNICOS EN CADA DATAFRAME\n",
      "Títulos únicos en df_concesiones: 592469\n",
      "Títulos únicos en df_subterraneas: 356989\n",
      "Títulos únicos en df_superficiales: 130314\n",
      "\n",
      "Títulos que aparecen en concesiones Y subterráneas: 356988\n",
      "Títulos que aparecen en concesiones Y superficiales: 130314\n",
      "Títulos que aparecen en los TRES dataframes: 909\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTÍTULOS ÚNICOS EN CADA DATAFRAME\")\n",
    "titulos_concesiones = set(df_concesiones.select('titulo').unique().to_series().to_list())\n",
    "titulos_subterraneas = set(df_subterraneas.select('titulo').unique().to_series().to_list())\n",
    "titulos_superficiales = set(df_superficiales.select('titulo').unique().to_series().to_list())\n",
    "\n",
    "print(f\"Títulos únicos en df_concesiones: {len(titulos_concesiones)}\")\n",
    "print(f\"Títulos únicos en df_subterraneas: {len(titulos_subterraneas)}\")\n",
    "print(f\"Títulos únicos en df_superficiales: {len(titulos_superficiales)}\")\n",
    "\n",
    "# Intersecciones\n",
    "titulos_en_subterraneas_y_concesiones = titulos_concesiones.intersection(titulos_subterraneas)\n",
    "titulos_en_superficiales_y_concesiones = titulos_concesiones.intersection(titulos_superficiales)\n",
    "titulos_en_todos = titulos_concesiones.intersection(titulos_subterraneas).intersection(titulos_superficiales)\n",
    "\n",
    "print(f\"\\nTítulos que aparecen en concesiones Y subterráneas: {len(titulos_en_subterraneas_y_concesiones)}\")\n",
    "print(f\"Títulos que aparecen en concesiones Y superficiales: {len(titulos_en_superficiales_y_concesiones)}\")\n",
    "print(f\"Títulos que aparecen en los TRES dataframes: {len(titulos_en_todos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d933fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar fechas en los dataframes subterráneas y superficiales (similar a concesiones)\n",
    "df_subterraneas = manipulator.date_string_to_date(df_subterraneas)\n",
    "df_superficiales = manipulator.date_string_to_date(df_superficiales)\n",
    "\n",
    "# Truncar fechas para consistencia\n",
    "df_subterraneas = df_subterraneas.with_columns(\n",
    "    pl.col('ultimo_registro').dt.date().alias('ultimo_registro')\n",
    ")\n",
    "df_superficiales = df_superficiales.with_columns(\n",
    "    pl.col('ultimo_registro').dt.date().alias('ultimo_registro')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d703ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS DE COMPARACIÓN DE APROVECHAMIENTOS Y VOLÚMENES POR TÍTULO\n",
    "\n",
    "def comparar_aprovechamientos_y_volumenes(titulos_concesiones,titulos_subterraneas,titulos_superficiales):\n",
    "    \"\"\"\n",
    "    Compara los aprovechamientos y volúmenes entre df_concesiones, df_subterraneas y df_superficiales\n",
    "    por título a lo largo de los períodos.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identificar columnas de volumen en cada dataframe\n",
    "    vol_cols_concesiones = [col for col in df_concesiones.columns if 'volumen' in col.lower()]\n",
    "    vol_cols_subterraneas = [col for col in df_subterraneas.columns if 'volumen' in col.lower()]\n",
    "    vol_cols_superficiales = [col for col in df_superficiales.columns if 'volumen' in col.lower()]\n",
    "\n",
    "    print(\"COLUMNAS RELACIONADAS CON EL VOLUMEN\")\n",
    "    print(\"df_concesiones:\")\n",
    "    for col in vol_cols_concesiones:\n",
    "        print(f\"  - {col}\")\n",
    "    print(\"\\ndf_subterraneas:\")\n",
    "    for col in vol_cols_subterraneas:\n",
    "        print(f\"  - {col}\")\n",
    "    print(\"\\ndf_superficiales:\")\n",
    "    for col in vol_cols_superficiales:\n",
    "        print(f\"  - {col}\")\n",
    "    \n",
    "    \n",
    "    # Títulos para comparables\n",
    "    titulos_sub_vs_conc = titulos_concesiones.intersection(titulos_subterraneas)\n",
    "    titulos_sup_vs_conc = titulos_concesiones.intersection(titulos_superficiales)\n",
    "    \n",
    "    print(f\"\\nCantidad de titulos compalabres\")\n",
    "    print(f\"Títulos en concesiones Y subterráneas: {len(titulos_sub_vs_conc)}\")\n",
    "    print(f\"Títulos en concesiones Y superficiales: {len(titulos_sup_vs_conc)}\")\n",
    "    \n",
    "    return titulos_sub_vs_conc, titulos_sup_vs_conc, vol_cols_concesiones, vol_cols_subterraneas, vol_cols_superficiales\n",
    "\n",
    "# Ejecutar análisis inicial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9fe1b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNAS RELACIONADAS CON EL VOLUMEN\n",
      "df_concesiones:\n",
      "  - volumen_de_extraccion_anual_de_aguas_nacionales_que_ampara_el_titulo_en_m3\n",
      "  - volumen_de_extraccion_anual_de_aprovechamientos_superficiales_en_m3\n",
      "  - volumen_de_extraccion_anual_de_aprovechamientos_subterraneos_en_m3\n",
      "  - volumen_de_descarga_diario_en_m3\n",
      "\n",
      "df_subterraneas:\n",
      "  - volumen_anual_en_m3\n",
      "\n",
      "df_superficiales:\n",
      "  - volumen_anual_en_m3\n",
      "\n",
      "Cantidad de titulos compalabres\n",
      "Títulos en concesiones Y subterráneas: 356988\n",
      "Títulos en concesiones Y superficiales: 130314\n"
     ]
    }
   ],
   "source": [
    "titulos_sub_vs_conc, titulos_sup_vs_conc, vol_cols_concesiones, vol_cols_subterraneas, vol_cols_superficiales = comparar_aprovechamientos_y_volumenes(titulos_concesiones,titulos_subterraneas,titulos_superficiales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28ae14e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS DETALLADO DE INCONSISTENCIAS\n",
    "\n",
    "def analizar_inconsistencias_subterraneas():\n",
    "    \"\"\"\n",
    "    Compara df_concesiones vs df_subterraneas para el mismo título y período\n",
    "    \"\"\"\n",
    "    print(\"ANÁLISIS DE INCONSISTENCIAS: CONCESIONES vs SUBTERRÁNEAS (MISMO  TITULO Y PERIODO)\")\n",
    "    \n",
    "    # Preparar datos para comparación\n",
    "    concesiones_sub = df_concesiones.filter(\n",
    "        pl.col('titulo').is_in(list(titulos_sub_vs_conc)) #Filtramos para los titulos comparables\n",
    "    ).select([\n",
    "        'titulo', \n",
    "        'ultimo_registro', \n",
    "        'volumen_de_extraccion_anual_de_aprovechamientos_subterraneos_en_m3'\n",
    "    ]).rename({\n",
    "        'volumen_de_extraccion_anual_de_aprovechamientos_subterraneos_en_m3': 'vol_subterraneo_concesiones_anual'\n",
    "    })\n",
    "    \n",
    "    subterraneas_comp = df_subterraneas.select([\n",
    "        'titulo', \n",
    "        'ultimo_registro', \n",
    "        'volumen_anual_en_m3'\n",
    "    ]).rename({\n",
    "        'volumen_anual_en_m3': 'vol_subterraneo_directo_anual'\n",
    "    })\n",
    "    \n",
    "    # Join para comparar\n",
    "    comparacion_vol_subterranea = concesiones_sub.join(\n",
    "        subterraneas_comp, \n",
    "        on=['titulo', 'ultimo_registro'],  #join solo en estos campos  que coincidan \n",
    "        how='inner'\n",
    "    ).with_columns([\n",
    "        # Convertir a numérico y manejar nulos\n",
    "        pl.when(pl.col('vol_subterraneo_concesiones_anual').is_null())\n",
    "        .then(0.0)\n",
    "        .otherwise(pl.col('vol_subterraneo_concesiones_anual').cast(pl.Float64, strict=False))\n",
    "        .alias('vol_conc_num'), #Se crea esta columna para el volumen subterráneo de _concesiones\n",
    "\n",
    "        pl.when(pl.col('vol_subterraneo_directo_anual').is_null())\n",
    "        .then(0.0)\n",
    "        .otherwise(pl.col('vol_subterraneo_directo_anual').cast(pl.Float64, strict=False))\n",
    "        .alias('vol_sub_num') #Se crea esta columna para el volumen subterráneo de reportados\n",
    "    ]).with_columns([\n",
    "        # Calcular diferencias \n",
    "        (pl.col('vol_conc_num') - pl.col('vol_sub_num')).alias('diferencia_volumen'),\n",
    "        pl.when(pl.col('vol_conc_num') == pl.col('vol_sub_num'))\n",
    "        .then(True)\n",
    "        .otherwise(False)\n",
    "        .alias('volumenes_coinciden')\n",
    "    ])\n",
    "    #La función height de polars te da el número de filas \n",
    "    total_registros = comparacion_vol_subterranea.height\n",
    "    registros_coinciden = comparacion_vol_subterranea.filter(pl.col('volumenes_coinciden')).height\n",
    "    registros_difieren = total_registros - registros_coinciden\n",
    "    \n",
    "    print(f\"Total de registros comparables: {total_registros:,}\")\n",
    "    print(f\"Registros con volúmenes coincidentes: {registros_coinciden:,} ({registros_coinciden/total_registros*100:.2f}%)\")\n",
    "    print(f\"Registros con volúmenes diferentes: {registros_difieren:,} ({registros_difieren/total_registros*100:.2f}%)\")\n",
    "    \n",
    "    return comparacion_vol_subterranea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68fc915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analizar_inconsistencias_superficiales():\n",
    "    \"\"\"\n",
    "    Compara df_concesiones vs df_superficiales para el mismo título y período\n",
    "    \"\"\"\n",
    "    print(\"\\nANÁLISIS DE INCONSISTENCIAS: CONCESIONES vs SUPERFICIALES(MISMO  TITULO Y PERIODO)\")\n",
    "    \n",
    "    # Preparar datos para comparación\n",
    "    concesiones_sup = df_concesiones.filter(\n",
    "        pl.col('titulo').is_in(list(titulos_sup_vs_conc))\n",
    "    ).select([\n",
    "        'titulo', \n",
    "        'ultimo_registro', \n",
    "        'volumen_de_extraccion_anual_de_aprovechamientos_superficiales_en_m3'\n",
    "    ]).rename({\n",
    "        'volumen_de_extraccion_anual_de_aprovechamientos_superficiales_en_m3': 'vol_superficial_concesiones'\n",
    "    })\n",
    "    \n",
    "    superficiales_comp = df_superficiales.select([\n",
    "        'titulo', \n",
    "        'ultimo_registro', \n",
    "        'volumen_anual_en_m3'\n",
    "    ]).rename({\n",
    "        'volumen_anual_en_m3': 'vol_superficial_directo'\n",
    "    })\n",
    "    \n",
    "    # Join para comparar\n",
    "    comparacion_vol_superficial = concesiones_sup.join(\n",
    "        superficiales_comp, \n",
    "        on=['titulo', 'ultimo_registro'], \n",
    "        how='inner'\n",
    "    ).with_columns([\n",
    "        # Convertir a numérico y manejar nulos\n",
    "        pl.when(pl.col('vol_superficial_concesiones').is_null())\n",
    "        .then(0.0)\n",
    "        .otherwise(pl.col('vol_superficial_concesiones').cast(pl.Float64, strict=False))\n",
    "        .alias('vol_conc_num'),\n",
    "        \n",
    "        pl.when(pl.col('vol_superficial_directo').is_null())\n",
    "        .then(0.0)\n",
    "        .otherwise(pl.col('vol_superficial_directo').cast(pl.Float64, strict=False))\n",
    "        .alias('vol_sup_num')\n",
    "    ]).with_columns([\n",
    "        # Calcular diferencias\n",
    "        (pl.col('vol_conc_num') - pl.col('vol_sup_num')).alias('diferencia_volumen'),\n",
    "        pl.when(pl.col('vol_conc_num') == pl.col('vol_sup_num'))\n",
    "        .then(True)\n",
    "        .otherwise(False)\n",
    "        .alias('volumenes_coinciden')\n",
    "    ])\n",
    "    \n",
    "    total_registros = comparacion_vol_superficial.height\n",
    "    registros_coinciden = comparacion_vol_superficial.filter(pl.col('volumenes_coinciden')).height\n",
    "    registros_difieren = total_registros - registros_coinciden\n",
    "    \n",
    "    print(f\"Total de registros comparables: {total_registros:,}\")\n",
    "    print(f\"Registros con volúmenes coincidentes: {registros_coinciden:,} ({registros_coinciden/total_registros*100:.2f}%)\")\n",
    "    print(f\"Registros con volúmenes diferentes: {registros_difieren:,} ({registros_difieren/total_registros*100:.2f}%)\")\n",
    "    \n",
    "    return comparacion_vol_superficial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39cc6894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANÁLISIS DE INCONSISTENCIAS: CONCESIONES vs SUBTERRÁNEAS (MISMO  TITULO Y PERIODO)\n",
      "Total de registros comparables: 7,746,822\n",
      "Registros con volúmenes coincidentes: 5,540,380 (71.52%)\n",
      "Registros con volúmenes diferentes: 2,206,442 (28.48%)\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar análisis\n",
    "comp_subterraneas = analizar_inconsistencias_subterraneas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f4cf008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANÁLISIS DE INCONSISTENCIAS: CONCESIONES vs SUPERFICIALES(MISMO  TITULO Y PERIODO)\n",
      "Total de registros comparables: 2,953,039\n",
      "Registros con volúmenes coincidentes: 2,361,373 (79.96%)\n",
      "Registros con volúmenes diferentes: 591,666 (20.04%)\n"
     ]
    }
   ],
   "source": [
    "comp_superficiales = analizar_inconsistencias_superficiales()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ebb8e1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear métricas de discrepancias binarias para subterráneas\n",
    "discrepancias_sub_binarias = comp_subterraneas.group_by('titulo').agg([\n",
    "    # Si hay al menos una discrepancia, marcar como 1, sino 0\n",
    "    pl.when(pl.col('volumenes_coinciden').sum() < pl.col('volumenes_coinciden').count())\n",
    "    .then(1)\n",
    "    .otherwise(0)\n",
    "    .alias('Discrepancia_V_Subterraneo')\n",
    "])\n",
    "\n",
    "# Crear métricas de discrepancias binarias para superficiales\n",
    "discrepancias_sup_binarias = comp_superficiales.group_by('titulo').agg([\n",
    "    # Si hay al menos una discrepancia, marcar como 1, sino 0\n",
    "    pl.when(pl.col('volumenes_coinciden').sum() < pl.col('volumenes_coinciden').count())\n",
    "    .then(1)\n",
    "    .otherwise(0)\n",
    "    .alias('Discrepancia_V_Superficial')\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc6ad098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar las columnas al df_anomalias\n",
    "df_anomalias = df_anomalias.join(\n",
    "    discrepancias_sub_binarias, \n",
    "    on='titulo', \n",
    "    how='left'\n",
    ").join(\n",
    "    discrepancias_sup_binarias, \n",
    "    on='titulo', \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ab6dc63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANÁLISIS ESTADÍSTICO DE LAS DISCREPANCIAS (CORREGIDO)\n",
    "\n",
    "def analizar_discrepancias_estadisticas_v2(comparacion_df, tipo_agua):\n",
    "    \"\"\"\n",
    "    Analiza estadísticamente las discrepancias encontradas - versión corregida\n",
    "    \"\"\"\n",
    "    print(f\"\\nESTADÍSTICAS DE DISCREPANCIAS - {tipo_agua.upper()}\")\n",
    "    \n",
    "    # Filtrar solo registros con diferencias\n",
    "    discrepancias = comparacion_df.filter(~pl.col('volumenes_coinciden'))\n",
    "    \n",
    "    if discrepancias.height == 0:\n",
    "        print(\"No hay discrepancias para analizar\")\n",
    "        return None, None, None\n",
    "    \n",
    "    print(f\"Total de discrepancias: {discrepancias.height:,}\")\n",
    "    \n",
    "    # Estadísticas básicas de diferencias\n",
    "    stats = discrepancias.select([\n",
    "        pl.col('diferencia_volumen').abs().alias('diff_abs')\n",
    "    ]).select([\n",
    "        pl.col('diff_abs').min().alias('min_diff'),\n",
    "        pl.col('diff_abs').max().alias('max_diff'),\n",
    "        pl.col('diff_abs').mean().alias('mean_diff'),\n",
    "        pl.col('diff_abs').median().alias('median_diff'),\n",
    "        pl.col('diff_abs').std().alias('std_diff'),\n",
    "        pl.col('diff_abs').quantile(0.25).alias('q25_diff'),\n",
    "        pl.col('diff_abs').quantile(0.75).alias('q75_diff'),\n",
    "        pl.col('diff_abs').quantile(0.95).alias('q95_diff'),\n",
    "        pl.col('diff_abs').quantile(0.99).alias('q99_diff')\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nEstadísticas de diferencias absolutas de volumen:\")\n",
    "    for col in stats.columns:\n",
    "        val = stats.select(col).item()\n",
    "        if val is not None:\n",
    "            print(f\"  {col}: {val:,.2f} m³\")\n",
    "    \n",
    "    # Casos más extremos\n",
    "    print(f\"\\nCasos con mayores discrepancias:\")\n",
    "    casos_extremos = discrepancias.select([\n",
    "        'titulo', 'ultimo_registro', 'vol_conc_num', 'vol_sub_num' if 'vol_sub_num' in discrepancias.columns else 'vol_sup_num',\n",
    "        'diferencia_volumen'\n",
    "    ]).with_columns([\n",
    "        pl.col('diferencia_volumen').abs().alias('diff_abs')\n",
    "    ]).sort('diff_abs', descending=True).head(10)\n",
    "    \n",
    "    print(casos_extremos)\n",
    "    \n",
    "    return discrepancias, stats, casos_extremos\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f76c3ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando discrepancias en aguas subterráneas...\n",
      "\n",
      "ESTADÍSTICAS DE DISCREPANCIAS - SUBTERRÁNEAS\n",
      "Total de discrepancias: 2,206,442\n",
      "\n",
      "Estadísticas de diferencias absolutas de volumen:\n",
      "  min_diff: 0.01 m³\n",
      "  max_diff: 780,484,464.00 m³\n",
      "  mean_diff: 8,873,835.66 m³\n",
      "  median_diff: 29,483.14 m³\n",
      "  std_diff: 69,936,292.08 m³\n",
      "  q25_diff: 10,000.00 m³\n",
      "  q75_diff: 150,000.00 m³\n",
      "  q95_diff: 8,293,968.00 m³\n",
      "  q99_diff: 154,009,650.92 m³\n",
      "\n",
      "Casos con mayores discrepancias:\n",
      "shape: (10, 6)\n",
      "┌──────────────────┬─────────────────┬──────────────┬─────────────┬─────────────────┬──────────────┐\n",
      "│ titulo           ┆ ultimo_registro ┆ vol_conc_num ┆ vol_sub_num ┆ diferencia_volu ┆ diff_abs     │\n",
      "│ ---              ┆ ---             ┆ ---          ┆ ---         ┆ men             ┆ ---          │\n",
      "│ str              ┆ date            ┆ f64          ┆ f64         ┆ ---             ┆ f64          │\n",
      "│                  ┆                 ┆              ┆             ┆ f64             ┆              │\n",
      "╞══════════════════╪═════════════════╪══════════════╪═════════════╪═════════════════╪══════════════╡\n",
      "│ 13DFE100309/26HM ┆ 2019-04-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "│ 13DFE100309/26HM ┆ 2019-10-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "│ 13DFE100309/26HM ┆ 2020-01-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "│ 13DFE100309/26HM ┆ 2020-02-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "│ 13DFE100309/26HM ┆ 2020-06-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "│ 13DFE100309/26HM ┆ 2020-09-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "│ 13DFE100309/26HM ┆ 2020-12-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "│ 13DFE100309/26HM ┆ 2021-03-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "│ 13DFE100309/26HM ┆ 2021-06-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "│ 13DFE100309/26HM ┆ 2021-12-01      ┆ 7.80516e8    ┆ 31536.0     ┆ 7.80484464e8    ┆ 7.80484464e8 │\n",
      "│ GC18             ┆                 ┆              ┆             ┆                 ┆              │\n",
      "└──────────────────┴─────────────────┴──────────────┴─────────────┴─────────────────┴──────────────┘\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Analizar discrepancias para subterráneas\n",
    "print(\"Analizando discrepancias en aguas subterráneas...\")\n",
    "disc_sub, stats_sub, casos_sub = analizar_discrepancias_estadisticas_v2(comp_subterraneas, \"subterráneas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "355a3388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analizando discrepancias en aguas superficiales...\n",
      "\n",
      "ESTADÍSTICAS DE DISCREPANCIAS - SUPERFICIALES\n",
      "Total de discrepancias: 591,666\n",
      "\n",
      "Estadísticas de diferencias absolutas de volumen:\n",
      "  min_diff: 0.01 m³\n",
      "  max_diff: 3,393,588,595.00 m³\n",
      "  mean_diff: 1,362,054.80 m³\n",
      "  median_diff: 83,603.72 m³\n",
      "  std_diff: 33,239,709.54 m³\n",
      "  q25_diff: 15,552.00 m³\n",
      "  q75_diff: 369,000.00 m³\n",
      "  q95_diff: 1,521,450.00 m³\n",
      "  q99_diff: 13,931,912.60 m³\n",
      "\n",
      "Casos con mayores discrepancias:\n",
      "shape: (10, 6)\n",
      "┌───────────────────┬─────────────────┬──────────────┬──────────────┬───────────────────┬──────────┐\n",
      "│ titulo            ┆ ultimo_registro ┆ vol_conc_num ┆ vol_sup_num  ┆ diferencia_volume ┆ diff_abs │\n",
      "│ ---               ┆ ---             ┆ ---          ┆ ---          ┆ n                 ┆ ---      │\n",
      "│ str               ┆ date            ┆ f64          ┆ f64          ┆ ---               ┆ f64      │\n",
      "│                   ┆                 ┆              ┆              ┆ f64               ┆          │\n",
      "╞═══════════════════╪═════════════════╪══════════════╪══════════════╪═══════════════════╪══════════╡\n",
      "│ 10PUE100218/27JAG ┆ 2019-04-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "│ 10PUE100218/27JAG ┆ 2019-10-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "│ 10PUE100218/27JAG ┆ 2020-01-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "│ 10PUE100218/27JAG ┆ 2020-02-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "│ 10PUE100218/27JAG ┆ 2020-06-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "│ 10PUE100218/27JAG ┆ 2020-09-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "│ 10PUE100218/27JAG ┆ 2020-12-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "│ 10PUE100218/27JAG ┆ 2021-03-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "│ 10PUE100218/27JAG ┆ 2021-06-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "│ 10PUE100218/27JAG ┆ 2021-12-01      ┆ 3.5586e9     ┆ 1.65027815e8 ┆ 3.3936e9          ┆ 3.3936e9 │\n",
      "│ C18               ┆                 ┆              ┆              ┆                   ┆          │\n",
      "└───────────────────┴─────────────────┴──────────────┴──────────────┴───────────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "# Analizar discrepancias para superficiales  \n",
    "print(\"Analizando discrepancias en aguas superficiales...\")\n",
    "disc_sup, stats_sup, casos_sup = analizar_discrepancias_estadisticas_v2(comp_superficiales, \"superficiales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bcc565ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANÁLISIS POR TÍTULO - SUBTERRÁNEAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Títulos con discrepancias: 27,530\n",
      "Top 10 títulos con mayores discrepancias promedio:\n",
      "shape: (10, 5)\n",
      "┌───────────────────┬───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
      "│ titulo            ┆ num_discrepancias ┆ discrepancia_prom ┆ discrepancia_maxi ┆ periodos_con_dis │\n",
      "│ ---               ┆ ---               ┆ edio              ┆ ma                ┆ crepancias       │\n",
      "│ str               ┆ u32               ┆ ---               ┆ ---               ┆ ---              │\n",
      "│                   ┆                   ┆ f64               ┆ f64               ┆ u32              │\n",
      "╞═══════════════════╪═══════════════════╪═══════════════════╪═══════════════════╪══════════════════╡\n",
      "│ 13DFE100309/26HMG ┆ 17160             ┆ 7.7961e8          ┆ 7.80484464e8      ┆ 20               │\n",
      "│ C18               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 13MEX100314/26HMS ┆ 80                ┆ 1.5447e8          ┆ 1.9001e8          ┆ 20               │\n",
      "│ G98               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 06NVL100310/24HSG ┆ 5900              ┆ 1.5383e8          ┆ 1.5436e8          ┆ 20               │\n",
      "│ C02               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 6YUC100614/32HMGE ┆ 1740              ┆ 1.4393e8          ┆ 1.45128672e8      ┆ 20               │\n",
      "│ 94                ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 06CHI100312/24HMG ┆ 2400              ┆ 1.309e8           ┆ 1.319033e8        ┆ 20               │\n",
      "│ C07               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 13MEX104263/26HSG ┆ 6660              ┆ 1.1152e8          ┆ 1.1186066e8       ┆ 20               │\n",
      "│ R99               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 12QNR103439/32HMD ┆ 3740              ┆ 1.0135e8          ┆ 1.01577359e8      ┆ 20               │\n",
      "│ L08               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 04PUE100303/18HMD ┆ 2640              ┆ 9.6473e7          ┆ 9.7146e7          ┆ 20               │\n",
      "│ L16               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 08JAL100308/12HSD ┆ 3880              ┆ 9.4054e7          ┆ 9.4592232e7       ┆ 20               │\n",
      "│ A18               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 13MEX104245/26HSD ┆ 740               ┆ 8.8669764e7       ┆ 9.0910485e7       ┆ 20               │\n",
      "│ A16               ┆                   ┆                   ┆                   ┆                  │\n",
      "└───────────────────┴───────────────────┴───────────────────┴───────────────────┴──────────────────┘\n",
      "\n",
      "ANÁLISIS TEMPORAL - SUBTERRÁNEAS\n",
      "Discrepancias por período (primeros 10):\n",
      "shape: (10, 4)\n",
      "┌─────────────────┬───────────────────┬───────────────────────┬───────────────────┐\n",
      "│ ultimo_registro ┆ num_discrepancias ┆ discrepancia_promedio ┆ titulos_afectados │\n",
      "│ ---             ┆ ---               ┆ ---                   ┆ ---               │\n",
      "│ date            ┆ u32               ┆ f64                   ┆ u32               │\n",
      "╞═════════════════╪═══════════════════╪═══════════════════════╪═══════════════════╡\n",
      "│ 2019-04-01      ┆ 108000            ┆ 9.0544e6              ┆ 21895             │\n",
      "│ 2019-10-01      ┆ 108257            ┆ 9.0335e6              ┆ 21993             │\n",
      "│ 2020-01-01      ┆ 108411            ┆ 9.0209e6              ┆ 22049             │\n",
      "│ 2020-02-01      ┆ 108262            ┆ 9.0354e6              ┆ 22003             │\n",
      "│ 2020-06-01      ┆ 108529            ┆ 9.0113e6              ┆ 22134             │\n",
      "│ 2020-09-01      ┆ 108900            ┆ 8.9798e6              ┆ 22302             │\n",
      "│ 2020-12-01      ┆ 109277            ┆ 8.9477e6              ┆ 22473             │\n",
      "│ 2021-03-01      ┆ 109450            ┆ 8.9228e6              ┆ 22549             │\n",
      "│ 2021-06-01      ┆ 109710            ┆ 8.9114e6              ┆ 22650             │\n",
      "│ 2021-12-01      ┆ 110353            ┆ 8.8862e6              ┆ 22871             │\n",
      "└─────────────────┴───────────────────┴───────────────────────┴───────────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5046/1528320553.py:11: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias('num_discrepancias'),\n",
      "/tmp/ipykernel_5046/1528320553.py:24: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias('num_discrepancias'),\n",
      "/tmp/ipykernel_5046/1528320553.py:34: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias('total_registros'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Títulos con menor consistencia (menores porcentajes de coincidencia):\n",
      "shape: (10, 4)\n",
      "┌──────────────────────┬─────────────────┬────────────────────────┬─────────────────────────┐\n",
      "│ titulo               ┆ total_registros ┆ registros_coincidentes ┆ porcentaje_consistencia │\n",
      "│ ---                  ┆ ---             ┆ ---                    ┆ ---                     │\n",
      "│ str                  ┆ u32             ┆ u32                    ┆ f64                     │\n",
      "╞══════════════════════╪═════════════════╪════════════════════════╪═════════════════════════╡\n",
      "│ 04TLX150157/18HMDL18 ┆ 40              ┆ 0                      ┆ 0.0                     │\n",
      "│ 06COA108159/24ASGE99 ┆ 40              ┆ 0                      ┆ 0.0                     │\n",
      "│ 858893               ┆ 8               ┆ 0                      ┆ 0.0                     │\n",
      "│ 05GRO115745/19ESOC07 ┆ 60              ┆ 0                      ┆ 0.0                     │\n",
      "│ 13HGO100055/26IMDL08 ┆ 300             ┆ 0                      ┆ 0.0                     │\n",
      "│ 08GUA112429/12AMDL16 ┆ 30              ┆ 0                      ┆ 0.0                     │\n",
      "│ 12YUC156924/32AMDA15 ┆ 40              ┆ 0                      ┆ 0.0                     │\n",
      "│ AGS101238            ┆ 18              ┆ 0                      ┆ 0.0                     │\n",
      "│ 09SLP102717/26IMDL08 ┆ 40              ┆ 0                      ┆ 0.0                     │\n",
      "│ 02SON125499/09AMDA17 ┆ 40              ┆ 0                      ┆ 0.0                     │\n",
      "└──────────────────────┴─────────────────┴────────────────────────┴─────────────────────────┘\n",
      "\n",
      "================================================================================\n",
      "\n",
      "ANÁLISIS POR TÍTULO - SUPERFICIALES\n",
      "Títulos con discrepancias: 6,678\n",
      "Top 10 títulos con mayores discrepancias promedio:\n",
      "shape: (10, 5)\n",
      "┌───────────────────┬───────────────────┬───────────────────┬───────────────────┬──────────────────┐\n",
      "│ titulo            ┆ num_discrepancias ┆ discrepancia_prom ┆ discrepancia_maxi ┆ periodos_con_dis │\n",
      "│ ---               ┆ ---               ┆ edio              ┆ ma                ┆ crepancias       │\n",
      "│ str               ┆ u32               ┆ ---               ┆ ---               ┆ ---              │\n",
      "│                   ┆                   ┆ f64               ┆ f64               ┆ u32              │\n",
      "╞═══════════════════╪═══════════════════╪═══════════════════╪═══════════════════╪══════════════════╡\n",
      "│ 10PUE100218/27JAG ┆ 80                ┆ 2.6690e9          ┆ 3.3936e9          ┆ 20               │\n",
      "│ C18               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 10VER136746/28JAD ┆ 60                ┆ 3.1939e8          ┆ 3.6319e8          ┆ 20               │\n",
      "│ A17               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 06NVL100310/24HSG ┆ 140               ┆ 3.0508e8          ┆ 3.55932e8         ┆ 20               │\n",
      "│ C02               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 13DFE100309/26HMG ┆ 360               ┆ 2.918832e8        ┆ 3.08989728e8      ┆ 20               │\n",
      "│ C18               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ JAL125681         ┆ 16                ┆ 2.436156e8        ┆ 2.99592e8         ┆ 4                │\n",
      "│ 12CAM154128       ┆ 3                 ┆ 2.3695e8          ┆ 3.15799555e8      ┆ 1                │\n",
      "│ CAM154128         ┆ 12                ┆ 2.3695e8          ┆ 3.15799555e8      ┆ 4                │\n",
      "│ 10VER100230/28JAO ┆ 40                ┆ 2.2459e8          ┆ 2.51127658e8      ┆ 20               │\n",
      "│ C12               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 08JAL125681/12HSD ┆ 48                ┆ 2.165472e8        ┆ 2.99592e8         ┆ 16               │\n",
      "│ A18               ┆                   ┆                   ┆                   ┆                  │\n",
      "│ 10VER102534/28IAD ┆ 100               ┆ 9.6105e7          ┆ 1.19104189e8      ┆ 20               │\n",
      "│ A17               ┆                   ┆                   ┆                   ┆                  │\n",
      "└───────────────────┴───────────────────┴───────────────────┴───────────────────┴──────────────────┘\n",
      "\n",
      "ANÁLISIS TEMPORAL - SUPERFICIALES\n",
      "Discrepancias por período (primeros 10):\n",
      "shape: (10, 4)\n",
      "┌─────────────────┬───────────────────┬───────────────────────┬───────────────────┐\n",
      "│ ultimo_registro ┆ num_discrepancias ┆ discrepancia_promedio ┆ titulos_afectados │\n",
      "│ ---             ┆ ---               ┆ ---                   ┆ ---               │\n",
      "│ date            ┆ u32               ┆ f64                   ┆ u32               │\n",
      "╞═════════════════╪═══════════════════╪═══════════════════════╪═══════════════════╡\n",
      "│ 2019-04-01      ┆ 29520             ┆ 1.3428e6              ┆ 6137              │\n",
      "│ 2019-10-01      ┆ 29520             ┆ 1.3428e6              ┆ 6137              │\n",
      "│ 2020-01-01      ┆ 29529             ┆ 1.3424e6              ┆ 6141              │\n",
      "│ 2020-02-01      ┆ 29527             ┆ 1.3426e6              ┆ 6140              │\n",
      "│ 2020-06-01      ┆ 29541             ┆ 1.3417e6              ┆ 6152              │\n",
      "│ 2020-09-01      ┆ 29548             ┆ 1.3405e6              ┆ 6155              │\n",
      "│ 2020-12-01      ┆ 29543             ┆ 1.3402e6              ┆ 6147              │\n",
      "│ 2021-03-01      ┆ 29565             ┆ 1.3472e6              ┆ 6152              │\n",
      "│ 2021-06-01      ┆ 29564             ┆ 1.3478e6              ┆ 6151              │\n",
      "│ 2021-12-01      ┆ 29551             ┆ 1.3483e6              ┆ 6150              │\n",
      "└─────────────────┴───────────────────┴───────────────────────┴───────────────────┘\n",
      "\n",
      "Títulos con menor consistencia (menores porcentajes de coincidencia):\n",
      "shape: (10, 4)\n",
      "┌──────────────────────┬─────────────────┬────────────────────────┬─────────────────────────┐\n",
      "│ titulo               ┆ total_registros ┆ registros_coincidentes ┆ porcentaje_consistencia │\n",
      "│ ---                  ┆ ---             ┆ ---                    ┆ ---                     │\n",
      "│ str                  ┆ u32             ┆ u32                    ┆ f64                     │\n",
      "╞══════════════════════╪═════════════════╪════════════════════════╪═════════════════════════╡\n",
      "│ 08ZAC156105/12GDDL14 ┆ 40              ┆ 0                      ┆ 0.0                     │\n",
      "│ 09VER161964/26AADA23 ┆ 15              ┆ 0                      ┆ 0.0                     │\n",
      "│ 09QRO104627/26GHGE99 ┆ 160             ┆ 0                      ┆ 0.0                     │\n",
      "│ 04MCH159989/18AODL17 ┆ 60              ┆ 0                      ┆ 0.0                     │\n",
      "│ 11CHS105834/30GAGR98 ┆ 40              ┆ 0                      ┆ 0.0                     │\n",
      "│ 04OAX121128/18HSDA09 ┆ 27              ┆ 0                      ┆ 0.0                     │\n",
      "│ 08COL103607/16GOGE98 ┆ 40              ┆ 0                      ┆ 0.0                     │\n",
      "│ 08MEX105815/12HOGE99 ┆ 160             ┆ 0                      ┆ 0.0                     │\n",
      "│ 05GRO159300/18HODL17 ┆ 60              ┆ 0                      ┆ 0.0                     │\n",
      "│ 11CHS126461/30HOGR99 ┆ 40              ┆ 0                      ┆ 0.0                     │\n",
      "└──────────────────────┴─────────────────┴────────────────────────┴─────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "#ANÁLISIS POR TÍTULO - IDENTIFICAR PATRONES DE INCONSISTENCIAS\n",
    "\n",
    "def analizar_inconsistencias_por_titulo(comp_df, disc_df, tipo_agua):\n",
    "    \"\"\"\n",
    "    Analiza las inconsistencias agrupadas por título para identificar patrones\n",
    "    \"\"\"\n",
    "    print(f\"\\nANÁLISIS POR TÍTULO - {tipo_agua.upper()}\")\n",
    "    \n",
    "    # Análisis por título\n",
    "    titulos_problematicos = disc_df.group_by('titulo').agg([\n",
    "        pl.count().alias('num_discrepancias'),\n",
    "        pl.col('diferencia_volumen').abs().mean().alias('discrepancia_promedio'),\n",
    "        pl.col('diferencia_volumen').abs().max().alias('discrepancia_maxima'),\n",
    "        pl.col('ultimo_registro').n_unique().alias('periodos_con_discrepancias')\n",
    "    ]).sort('discrepancia_promedio', descending=True)\n",
    "    \n",
    "    print(f\"Títulos con discrepancias: {titulos_problematicos.height:,}\")\n",
    "    print(f\"Top 10 títulos con mayores discrepancias promedio:\")\n",
    "    print(titulos_problematicos.head(10))\n",
    "    \n",
    "    # Análisis temporal\n",
    "    print(f\"\\nANÁLISIS TEMPORAL - {tipo_agua.upper()}\")\n",
    "    discrepancias_temporales = disc_df.group_by('ultimo_registro').agg([\n",
    "        pl.count().alias('num_discrepancias'),\n",
    "        pl.col('diferencia_volumen').abs().mean().alias('discrepancia_promedio'),\n",
    "        pl.col('titulo').n_unique().alias('titulos_afectados')\n",
    "    ]).sort('ultimo_registro')\n",
    "    \n",
    "    print(\"Discrepancias por período (primeros 10):\")\n",
    "    print(discrepancias_temporales.head(10))\n",
    "    \n",
    "    # Resumen de consistencia por título\n",
    "    total_comp = comp_df.group_by('titulo').agg([\n",
    "        pl.count().alias('total_registros'),\n",
    "        pl.col('volumenes_coinciden').sum().alias('registros_coincidentes')\n",
    "    ]).with_columns([\n",
    "        (pl.col('registros_coincidentes') / pl.col('total_registros') * 100).alias('porcentaje_consistencia')\n",
    "    ]).sort('porcentaje_consistencia')\n",
    "    \n",
    "    print(f\"\\nTítulos con menor consistencia (menores porcentajes de coincidencia):\")\n",
    "    print(total_comp.head(10))\n",
    "    \n",
    "    return titulos_problematicos, discrepancias_temporales, total_comp\n",
    "\n",
    "# Ejecutar análisis por título\n",
    "if disc_sub is not None:\n",
    "    tit_prob_sub, disc_temp_sub, consist_sub = analizar_inconsistencias_por_titulo(comp_subterraneas, disc_sub, \"subterráneas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "if disc_sup is not None:\n",
    "    tit_prob_sup, disc_temp_sup, consist_sup = analizar_inconsistencias_por_titulo(comp_superficiales, disc_sup, \"superficiales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97a89569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "RESUMEN CONSOLIDADO DEL ANÁLISIS\n",
      "====================================================================================================\n",
      "\n",
      "🔍 HALLAZGOS PRINCIPALES:\n",
      "\n",
      "1. COBERTURA DE DATOS:\n",
      "   • Títulos únicos en df_concesiones: 592,469\n",
      "   • Títulos únicos en df_subterraneas: 356,989\n",
      "   • Títulos únicos en df_superficiales: 130,314\n",
      "   • Títulos comparables (concesiones ∩ subterráneas): 356,988\n",
      "   • Títulos comparables (concesiones ∩ superficiales): 130,314\n",
      "\n",
      "2. CONSISTENCIA DE VOLÚMENES:\n",
      "   🌊 AGUAS SUBTERRÁNEAS:\n",
      "      • Registros comparables: 7,746,822\n",
      "      • Coincidencias: 5,540,380 (71.52%)\n",
      "      • Discrepancias: 2,206,442 (28.48%)\n",
      "   🏞️ AGUAS SUPERFICIALES:\n",
      "      • Registros comparables: 2,953,039\n",
      "      • Coincidencias: 2,361,373 (79.96%)\n",
      "      • Discrepancias: 591,666 (20.04%)\n",
      "\n",
      "3. SEVERIDAD DE DISCREPANCIAS:\n",
      "   🌊 SUBTERRÁNEAS: Mediana = 29,483.14 m³, Promedio = 8,873,835.66 m³\n",
      "   🏞️ SUPERFICIALES: Mediana = 83,603.72 m³, Promedio = 1,362,054.80 m³\n",
      "\n",
      "📊 INTERPRETACIÓN:\n",
      "   • Las aguas superficiales muestran MAYOR consistencia (80.0%)\n",
      "   • Las aguas subterráneas tienen MÁS discrepancias (28.5%)\n",
      "   • Esto sugiere posibles problemas de calidad de datos o diferencias en metodologías\n",
      "   • Las discrepancias son significativas en magnitud (promedio en millones de m³)\n",
      "\n",
      "⚠️ RECOMENDACIONES:\n",
      "   1. Investigar los títulos con mayor inconsistencia identificados\n",
      "   2. Revisar la metodología de captura de datos entre sistemas\n",
      "   3. Implementar validaciones cruzadas automáticas\n",
      "   4. Priorizar la limpieza de datos en registros subterráneos\n",
      "   5. Establecer alertas para discrepancias > umbral definido\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# RESUMEN CONSOLIDADO Y CONCLUSIONES\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"RESUMEN CONSOLIDADO DEL ANÁLISIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\n🔍 HALLAZGOS PRINCIPALES:\")\n",
    "\n",
    "print(f\"\\n1. COBERTURA DE DATOS:\")\n",
    "print(f\"   • Títulos únicos en df_concesiones: {len(titulos_concesiones):,}\")\n",
    "print(f\"   • Títulos únicos en df_subterraneas: {len(titulos_subterraneas):,}\")\n",
    "print(f\"   • Títulos únicos en df_superficiales: {len(titulos_superficiales):,}\")\n",
    "print(f\"   • Títulos comparables (concesiones ∩ subterráneas): {len(titulos_sub_vs_conc):,}\")\n",
    "print(f\"   • Títulos comparables (concesiones ∩ superficiales): {len(titulos_sup_vs_conc):,}\")\n",
    "\n",
    "print(f\"\\n2. CONSISTENCIA DE VOLÚMENES:\")\n",
    "total_sub = comp_subterraneas.height\n",
    "coincidentes_sub = comp_subterraneas.filter(pl.col('volumenes_coinciden')).height\n",
    "total_sup = comp_superficiales.height\n",
    "coincidentes_sup = comp_superficiales.filter(pl.col('volumenes_coinciden')).height\n",
    "\n",
    "print(f\"   🌊 AGUAS SUBTERRÁNEAS:\")\n",
    "print(f\"      • Registros comparables: {total_sub:,}\")\n",
    "print(f\"      • Coincidencias: {coincidentes_sub:,} ({coincidentes_sub/total_sub*100:.2f}%)\")\n",
    "print(f\"      • Discrepancias: {total_sub-coincidentes_sub:,} ({(total_sub-coincidentes_sub)/total_sub*100:.2f}%)\")\n",
    "\n",
    "print(f\"   🏞️ AGUAS SUPERFICIALES:\")\n",
    "print(f\"      • Registros comparables: {total_sup:,}\")\n",
    "print(f\"      • Coincidencias: {coincidentes_sup:,} ({coincidentes_sup/total_sup*100:.2f}%)\")\n",
    "print(f\"      • Discrepancias: {total_sup-coincidentes_sup:,} ({(total_sup-coincidentes_sup)/total_sup*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\n3. SEVERIDAD DE DISCREPANCIAS:\")\n",
    "if stats_sub is not None:\n",
    "    median_sub = stats_sub.select('median_diff').item()\n",
    "    mean_sub = stats_sub.select('mean_diff').item()\n",
    "    print(f\"   🌊 SUBTERRÁNEAS: Mediana = {median_sub:,.2f} m³, Promedio = {mean_sub:,.2f} m³\")\n",
    "\n",
    "if stats_sup is not None:\n",
    "    median_sup = stats_sup.select('median_diff').item()\n",
    "    mean_sup = stats_sup.select('mean_diff').item()\n",
    "    print(f\"   🏞️ SUPERFICIALES: Mediana = {median_sup:,.2f} m³, Promedio = {mean_sup:,.2f} m³\")\n",
    "\n",
    "print(f\"\\n📊 INTERPRETACIÓN:\")\n",
    "print(f\"   • Las aguas superficiales muestran MAYOR consistencia ({coincidentes_sup/total_sup*100:.1f}%)\")\n",
    "print(f\"   • Las aguas subterráneas tienen MÁS discrepancias ({(total_sub-coincidentes_sub)/total_sub*100:.1f}%)\")\n",
    "print(f\"   • Esto sugiere posibles problemas de calidad de datos o diferencias en metodologías\")\n",
    "print(f\"   • Las discrepancias son significativas en magnitud (promedio en millones de m³)\")\n",
    "\n",
    "print(f\"\\n⚠️ RECOMENDACIONES:\")\n",
    "print(f\"   1. Investigar los títulos con mayor inconsistencia identificados\")\n",
    "print(f\"   2. Revisar la metodología de captura de datos entre sistemas\")\n",
    "print(f\"   3. Implementar validaciones cruzadas automáticas\")\n",
    "print(f\"   4. Priorizar la limpieza de datos en registros subterráneos\")\n",
    "print(f\"   5. Establecer alertas para discrepancias > umbral definido\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dcee2c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREANDO MÉTRICAS DE DISCREPANCIAS POR TÍTULO\n",
      "Métricas subterráneas calculadas para 27,530 títulos\n",
      "Métricas superficiales calculadas para 6,678 títulos\n",
      "Consistencia subterráneas calculada para 356,988 títulos\n",
      "Consistencia superficiales calculada para 130,314 títulos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5046/1805708906.py:13: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias('discrepancias_subterraneas_count'),\n",
      "/tmp/ipykernel_5046/1805708906.py:25: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias('discrepancias_superficiales_count'),\n"
     ]
    }
   ],
   "source": [
    "# INTEGRACIÓN DE DISCREPANCIAS AL DF_ANOMALIAS\n",
    "\n",
    "def crear_metricas_discrepancias():\n",
    "    \"\"\"\n",
    "    Calcula métricas de discrepancias por título para integrar al df_anomalias\n",
    "    \"\"\"\n",
    "    print(\"CREANDO MÉTRICAS DE DISCREPANCIAS POR TÍTULO\")\n",
    "    \n",
    "    # === MÉTRICAS PARA AGUAS SUBTERRÁNEAS ===\n",
    "    metricas_sub = None\n",
    "    if disc_sub is not None and disc_sub.height > 0:\n",
    "        metricas_sub = disc_sub.group_by('titulo').agg([\n",
    "            pl.count().alias('discrepancias_subterraneas_count'),\n",
    "            pl.col('diferencia_volumen').abs().mean().alias('discrepancia_subterranea_promedio'),\n",
    "            pl.col('diferencia_volumen').abs().max().alias('discrepancia_subterranea_maxima'),\n",
    "            pl.col('diferencia_volumen').abs().median().alias('discrepancia_subterranea_mediana'),\n",
    "            pl.col('ultimo_registro').n_unique().alias('periodos_con_discrepancia_sub')\n",
    "        ])\n",
    "        print(f\"Métricas subterráneas calculadas para {metricas_sub.height:,} títulos\")\n",
    "    \n",
    "    # === MÉTRICAS PARA AGUAS SUPERFICIALES ===\n",
    "    metricas_sup = None\n",
    "    if disc_sup is not None and disc_sup.height > 0:\n",
    "        metricas_sup = disc_sup.group_by('titulo').agg([\n",
    "            pl.count().alias('discrepancias_superficiales_count'),\n",
    "            pl.col('diferencia_volumen').abs().mean().alias('discrepancia_superficial_promedio'),\n",
    "            pl.col('diferencia_volumen').abs().max().alias('discrepancia_superficial_maxima'),\n",
    "            pl.col('diferencia_volumen').abs().median().alias('discrepancia_superficial_mediana'),\n",
    "            pl.col('ultimo_registro').n_unique().alias('periodos_con_discrepancia_sup')\n",
    "        ])\n",
    "        print(f\"Métricas superficiales calculadas para {metricas_sup.height:,} títulos\")\n",
    "    \n",
    "    # === MÉTRICAS DE CONSISTENCIA GENERAL ===\n",
    "    # Para subterráneas\n",
    "    consistencia_sub = None\n",
    "    if 'consist_sub' in globals() and consist_sub is not None:\n",
    "        consistencia_sub = consist_sub.select([\n",
    "            'titulo',\n",
    "            'total_registros',\n",
    "            'registros_coincidentes', \n",
    "            'porcentaje_consistencia'\n",
    "        ]).rename({\n",
    "            'total_registros': 'total_registros_sub',\n",
    "            'registros_coincidentes': 'registros_coincidentes_sub',\n",
    "            'porcentaje_consistencia': 'porcentaje_consistencia_sub'\n",
    "        })\n",
    "        print(f\"Consistencia subterráneas calculada para {consistencia_sub.height:,} títulos\")\n",
    "    \n",
    "    # Para superficiales\n",
    "    consistencia_sup = None\n",
    "    if 'consist_sup' in globals() and consist_sup is not None:\n",
    "        consistencia_sup = consist_sup.select([\n",
    "            'titulo',\n",
    "            'total_registros',\n",
    "            'registros_coincidentes', \n",
    "            'porcentaje_consistencia'\n",
    "        ]).rename({\n",
    "            'total_registros': 'total_registros_sup',\n",
    "            'registros_coincidentes': 'registros_coincidentes_sup',\n",
    "            'porcentaje_consistencia': 'porcentaje_consistencia_sup'\n",
    "        })\n",
    "        print(f\"Consistencia superficiales calculada para {consistencia_sup.height:,} títulos\")\n",
    "    \n",
    "    return metricas_sub, metricas_sup, consistencia_sub, consistencia_sup\n",
    "\n",
    "# Ejecutar cálculo de métricas\n",
    "metricas_sub, metricas_sup, consistencia_sub, consistencia_sup = crear_metricas_discrepancias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05afb06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INTEGRANDO DISCREPANCIAS AL DF_ANOMALIAS ===\n",
      "✓ Métricas de discrepancias subterráneas integradas\n",
      "✓ Métricas de discrepancias superficiales integradas\n",
      "✓ Métricas de consistencia subterráneas integradas\n",
      "✓ Métricas de consistencia superficiales integradas\n",
      "\n",
      "=== RESULTADO DE LA INTEGRACIÓN ===\n",
      "Forma original de df_anomalias: (592469, 13)\n",
      "Forma expandida de df_anomalias_completo: (592469, 29)\n",
      "\n",
      "Nuevas columnas agregadas:\n",
      "  - discrepancias_subterraneas_count\n",
      "  - discrepancia_subterranea_promedio\n",
      "  - discrepancia_subterranea_maxima\n",
      "  - discrepancia_subterranea_mediana\n",
      "  - periodos_con_discrepancia_sub\n",
      "  - discrepancias_superficiales_count\n",
      "  - discrepancia_superficial_promedio\n",
      "  - discrepancia_superficial_maxima\n",
      "  - discrepancia_superficial_mediana\n",
      "  - periodos_con_discrepancia_sup\n",
      "  - total_registros_sub\n",
      "  - registros_coincidentes_sub\n",
      "  - porcentaje_consistencia_sub\n",
      "  - total_registros_sup\n",
      "  - registros_coincidentes_sup\n",
      "  - porcentaje_consistencia_sup\n"
     ]
    }
   ],
   "source": [
    "# INTEGRAR MÉTRICAS AL DF_ANOMALIAS\n",
    "\n",
    "def integrar_discrepancias_a_anomalias():\n",
    "    \"\"\"\n",
    "    Integra las métricas de discrepancias al dataframe df_anomalias existente\n",
    "    \"\"\"\n",
    "    print(\"=== INTEGRANDO DISCREPANCIAS AL DF_ANOMALIAS ===\")\n",
    "    \n",
    "    # Comenzar con el df_anomalias actual\n",
    "    df_anomalias_expandido = df_anomalias\n",
    "    \n",
    "    # === INTEGRAR MÉTRICAS DE SUBTERRÁNEAS ===\n",
    "    if metricas_sub is not None:\n",
    "        df_anomalias_expandido = df_anomalias_expandido.join(\n",
    "            metricas_sub, \n",
    "            on='titulo', \n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"✓ Métricas de discrepancias subterráneas integradas\")\n",
    "    else:\n",
    "        # Agregar columnas vacías si no hay métricas\n",
    "        df_anomalias_expandido = df_anomalias_expandido.with_columns([\n",
    "            pl.lit(None).alias('discrepancias_subterraneas_count'),\n",
    "            pl.lit(None).alias('discrepancia_subterranea_promedio'),\n",
    "            pl.lit(None).alias('discrepancia_subterranea_maxima'),\n",
    "            pl.lit(None).alias('discrepancia_subterranea_mediana'),\n",
    "            pl.lit(None).alias('periodos_con_discrepancia_sub')\n",
    "        ])\n",
    "    \n",
    "    # === INTEGRAR MÉTRICAS DE SUPERFICIALES ===\n",
    "    if metricas_sup is not None:\n",
    "        df_anomalias_expandido = df_anomalias_expandido.join(\n",
    "            metricas_sup, \n",
    "            on='titulo', \n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"✓ Métricas de discrepancias superficiales integradas\")\n",
    "    else:\n",
    "        # Agregar columnas vacías si no hay métricas\n",
    "        df_anomalias_expandido = df_anomalias_expandido.with_columns([\n",
    "            pl.lit(None).alias('discrepancias_superficiales_count'),\n",
    "            pl.lit(None).alias('discrepancia_superficial_promedio'),\n",
    "            pl.lit(None).alias('discrepancia_superficial_maxima'),\n",
    "            pl.lit(None).alias('discrepancia_superficial_mediana'),\n",
    "            pl.lit(None).alias('periodos_con_discrepancia_sup')\n",
    "        ])\n",
    "    \n",
    "    # === INTEGRAR MÉTRICAS DE CONSISTENCIA SUBTERRÁNEAS ===\n",
    "    if consistencia_sub is not None:\n",
    "        df_anomalias_expandido = df_anomalias_expandido.join(\n",
    "            consistencia_sub, \n",
    "            on='titulo', \n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"✓ Métricas de consistencia subterráneas integradas\")\n",
    "    else:\n",
    "        df_anomalias_expandido = df_anomalias_expandido.with_columns([\n",
    "            pl.lit(None).alias('total_registros_sub'),\n",
    "            pl.lit(None).alias('registros_coincidentes_sub'),\n",
    "            pl.lit(None).alias('porcentaje_consistencia_sub')\n",
    "        ])\n",
    "    \n",
    "    # === INTEGRAR MÉTRICAS DE CONSISTENCIA SUPERFICIALES ===\n",
    "    if consistencia_sup is not None:\n",
    "        df_anomalias_expandido = df_anomalias_expandido.join(\n",
    "            consistencia_sup, \n",
    "            on='titulo', \n",
    "            how='left'\n",
    "        )\n",
    "        print(f\"✓ Métricas de consistencia superficiales integradas\")\n",
    "    else:\n",
    "        df_anomalias_expandido = df_anomalias_expandido.with_columns([\n",
    "            pl.lit(None).alias('total_registros_sup'),\n",
    "            pl.lit(None).alias('registros_coincidentes_sup'),\n",
    "            pl.lit(None).alias('porcentaje_consistencia_sup')\n",
    "        ])\n",
    "    \n",
    "    return df_anomalias_expandido\n",
    "\n",
    "# Ejecutar integración\n",
    "df_anomalias_completo = integrar_discrepancias_a_anomalias()\n",
    "\n",
    "print(f\"\\n=== RESULTADO DE LA INTEGRACIÓN ===\")\n",
    "print(f\"Forma original de df_anomalias: {df_anomalias.shape}\")\n",
    "print(f\"Forma expandida de df_anomalias_completo: {df_anomalias_completo.shape}\")\n",
    "print(f\"\\nNuevas columnas agregadas:\")\n",
    "nuevas_columnas = [col for col in df_anomalias_completo.columns if col not in df_anomalias.columns]\n",
    "for col in nuevas_columnas:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a92f38c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREANDO SCORE DE ANOMALÍA INTEGRADO ===\n",
      "\n",
      "=== DISTRIBUCIÓN DE ANOMALÍAS ===\n",
      "shape: (5, 3)\n",
      "┌────────────────────────┬──────────┬────────────────┐\n",
      "│ clasificacion_anomalia ┆ cantidad ┆ score_promedio │\n",
      "│ ---                    ┆ ---      ┆ ---            │\n",
      "│ str                    ┆ u32      ┆ f64            │\n",
      "╞════════════════════════╪══════════╪════════════════╡\n",
      "│ CRÍTICA                ┆ 756      ┆ 17.238095      │\n",
      "│ ALTA                   ┆ 30409    ┆ 11.003091      │\n",
      "│ MEDIA                  ┆ 11041    ┆ 7.81623        │\n",
      "│ BAJA                   ┆ 517263   ┆ 2.789683       │\n",
      "│ SIN_ANOMALIAS          ┆ 33000    ┆ 0.0            │\n",
      "└────────────────────────┴──────────┴────────────────┘\n",
      "\n",
      "=== TOP 10 TÍTULOS CON MAYOR SCORE DE ANOMALÍA ===\n",
      "shape: (10, 7)\n",
      "┌──────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┬─────────────┐\n",
      "│ titulo       ┆ N_titulares ┆ Diferente_t ┆ porcentaje_ ┆ porcentaje_ ┆ score_anoma ┆ clasificaci │\n",
      "│ ---          ┆ ---         ┆ itular      ┆ consistenci ┆ consistenci ┆ lia_total   ┆ on_anomalia │\n",
      "│ str          ┆ i64         ┆ ---         ┆ a_sub       ┆ a_sup       ┆ ---         ┆ ---         │\n",
      "│              ┆             ┆ i64         ┆ ---         ┆ ---         ┆ f64         ┆ str         │\n",
      "│              ┆             ┆             ┆ f64         ┆ f64         ┆             ┆             │\n",
      "╞══════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╪═════════════╡\n",
      "│ 04PUE103357/ ┆ 1           ┆ null        ┆ 0.0         ┆ 0.0         ┆ 23.0        ┆ CRÍTICA     │\n",
      "│ 18ASGE00     ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "│ 6CHS100642/3 ┆ 2           ┆ 0           ┆ 0.0         ┆ null        ┆ 21.0        ┆ CRÍTICA     │\n",
      "│ 0APGE94      ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "│ 11CHS103721/ ┆ 2           ┆ 0           ┆ 0.0         ┆ null        ┆ 21.0        ┆ CRÍTICA     │\n",
      "│ 30HMOC07     ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "│ 08GUA120364/ ┆ 2           ┆ 0           ┆ 0.0         ┆ null        ┆ 21.0        ┆ CRÍTICA     │\n",
      "│ 12AMDL10     ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "│ 12YUC110233/ ┆ 2           ┆ 0           ┆ 0.0         ┆ null        ┆ 21.0        ┆ CRÍTICA     │\n",
      "│ 32IMGR00     ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "│ 6QNR100136/3 ┆ 2           ┆ 0           ┆ 0.0         ┆ null        ┆ 21.0        ┆ CRÍTICA     │\n",
      "│ 2EPGR94      ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "│ 07SLP110398/ ┆ 2           ┆ 0           ┆ 0.0         ┆ null        ┆ 21.0        ┆ CRÍTICA     │\n",
      "│ 37ASDL14     ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "│ 6YUC101670/3 ┆ 2           ┆ 0           ┆ 0.0         ┆ null        ┆ 21.0        ┆ CRÍTICA     │\n",
      "│ 2AMGE94      ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "│ 6YUC100873/3 ┆ 2           ┆ 0           ┆ 0.0         ┆ null        ┆ 21.0        ┆ CRÍTICA     │\n",
      "│ 2AMGE95      ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "│ 01BCS100147/ ┆ 2           ┆ 0           ┆ 0.0         ┆ null        ┆ 21.0        ┆ CRÍTICA     │\n",
      "│ 02AMDL15     ┆             ┆             ┆             ┆             ┆             ┆             │\n",
      "└──────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┴─────────────┘\n"
     ]
    }
   ],
   "source": [
    "# ANÁLISIS FINAL Y SCORE DE ANOMALÍA INTEGRADO\n",
    "\n",
    "def crear_score_anomalia_integrado(df):\n",
    "    \"\"\"\n",
    "    Crea un score de anomalía que integra todas las discrepancias encontradas\n",
    "    \"\"\"\n",
    "    print(\"=== CREANDO SCORE DE ANOMALÍA INTEGRADO ===\")\n",
    "    \n",
    "    df_scored = df.with_columns([\n",
    "        # Score de anomalías de titulares (ya existente)\n",
    "        pl.when(pl.col('N_titulares') > 1)\n",
    "        .then(\n",
    "            pl.when(pl.col('Diferente_titular') == 0)  # Titulares diferentes\n",
    "            .then(10.0)\n",
    "            .when(pl.col('Diferente_titular') == 2)    # Titulares dudosos\n",
    "            .then(5.0)\n",
    "            .otherwise(0.0)\n",
    "        )\n",
    "        .otherwise(0.0)\n",
    "        .alias('score_titulares'),\n",
    "        \n",
    "        # Score de discrepancias subterráneas\n",
    "        pl.when(pl.col('discrepancias_subterraneas_count').is_not_null())\n",
    "        .then(\n",
    "            pl.when(pl.col('porcentaje_consistencia_sub') < 50.0)\n",
    "            .then(8.0)\n",
    "            .when(pl.col('porcentaje_consistencia_sub') < 75.0)\n",
    "            .then(5.0)\n",
    "            .when(pl.col('porcentaje_consistencia_sub') < 90.0)\n",
    "            .then(3.0)\n",
    "            .otherwise(1.0)\n",
    "        )\n",
    "        .otherwise(0.0)\n",
    "        .alias('score_discrepancias_sub'),\n",
    "        \n",
    "        # Score de discrepancias superficiales\n",
    "        pl.when(pl.col('discrepancias_superficiales_count').is_not_null())\n",
    "        .then(\n",
    "            pl.when(pl.col('porcentaje_consistencia_sup') < 50.0)\n",
    "            .then(8.0)\n",
    "            .when(pl.col('porcentaje_consistencia_sup') < 75.0)\n",
    "            .then(5.0)\n",
    "            .when(pl.col('porcentaje_consistencia_sup') < 90.0)\n",
    "            .then(3.0)\n",
    "            .otherwise(1.0)\n",
    "        )\n",
    "        .otherwise(0.0)\n",
    "        .alias('score_discrepancias_sup'),\n",
    "        \n",
    "        # Score de anomalías de volumen (ya existente)\n",
    "        (\n",
    "            pl.when(pl.col('Anomalia_V_Total') > 1).then(2.0).otherwise(0.0) +\n",
    "            pl.when(pl.col('Anomalia_V_Subterraneo') > 1).then(2.0).otherwise(0.0) +\n",
    "            pl.when(pl.col('Anomalia_V_Superficial') > 1).then(2.0).otherwise(0.0)\n",
    "        ).alias('score_volumenes'),\n",
    "        \n",
    "        # Score de frecuencia de cambios\n",
    "        pl.when(pl.col('Cambios_en_20_periodos') > 15)\n",
    "        .then(3.0)\n",
    "        .when(pl.col('Cambios_en_20_periodos') > 10)\n",
    "        .then(2.0)\n",
    "        .when(pl.col('Cambios_en_20_periodos') > 5)\n",
    "        .then(1.0)\n",
    "        .otherwise(0.0)\n",
    "        .alias('score_frecuencia_cambios')\n",
    "    ])\n",
    "    \n",
    "    # Agregar score total en una operación separada\n",
    "    df_scored = df_scored.with_columns([\n",
    "        # Score total de anomalía\n",
    "        (\n",
    "            pl.col('score_titulares') + \n",
    "            pl.col('score_discrepancias_sub') + \n",
    "            pl.col('score_discrepancias_sup') + \n",
    "            pl.col('score_volumenes') + \n",
    "            pl.col('score_frecuencia_cambios')\n",
    "        ).alias('score_anomalia_total')\n",
    "    ])\n",
    "    \n",
    "    # Agregar clasificación en otra operación separada\n",
    "    df_scored = df_scored.with_columns([\n",
    "        # Clasificación de anomalía\n",
    "        pl.when(pl.col('score_anomalia_total') >= 15)\n",
    "        .then(pl.lit('CRÍTICA'))\n",
    "        .when(pl.col('score_anomalia_total') >= 10)\n",
    "        .then(pl.lit('ALTA'))\n",
    "        .when(pl.col('score_anomalia_total') >= 5)\n",
    "        .then(pl.lit('MEDIA'))\n",
    "        .when(pl.col('score_anomalia_total') > 0)\n",
    "        .then(pl.lit('BAJA'))\n",
    "        .otherwise(pl.lit('SIN_ANOMALIAS'))\n",
    "        .alias('clasificacion_anomalia')\n",
    "    ])\n",
    "    \n",
    "    return df_scored\n",
    "\n",
    "# Aplicar scoring\n",
    "df_anomalias_final = crear_score_anomalia_integrado(df_anomalias_completo)\n",
    "\n",
    "print(f\"\\n=== DISTRIBUCIÓN DE ANOMALÍAS ===\")\n",
    "distribucion = df_anomalias_final.group_by('clasificacion_anomalia').agg([\n",
    "    pl.len().alias('cantidad'),\n",
    "    pl.col('score_anomalia_total').mean().alias('score_promedio')\n",
    "]).sort('score_promedio', descending=True)\n",
    "\n",
    "print(distribucion)\n",
    "\n",
    "print(f\"\\n=== TOP 10 TÍTULOS CON MAYOR SCORE DE ANOMALÍA ===\")\n",
    "top_anomalias = df_anomalias_final.sort('score_anomalia_total', descending=True).head(10)\n",
    "print(top_anomalias.select([\n",
    "    'titulo', \n",
    "    'N_titulares',\n",
    "    'Diferente_titular',\n",
    "    'porcentaje_consistencia_sub',\n",
    "    'porcentaje_consistencia_sup',\n",
    "    'score_anomalia_total',\n",
    "    'clasificacion_anomalia'\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6376e445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "                    REPORTE FINAL DE ANÁLISIS DE ANOMALÍAS\n",
      "====================================================================================================\n",
      "\n",
      "RESUMEN EJECUTIVO:\n",
      "   • Total de títulos analizados: 592,469\n",
      "\n",
      "DISTRIBUCIÓN DE ANOMALÍAS:\n",
      "   • BAJA: 517,263 títulos (87.31%)\n",
      "   • SIN_ANOMALIAS: 33,000 títulos (5.57%)\n",
      "   • ALTA: 30,409 títulos (5.13%)\n",
      "   • MEDIA: 11,041 títulos (1.86%)\n",
      "   • CRÍTICA: 756 títulos (0.13%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚠️ TÍTULOS PRIORITARIOS:\n",
      "   • Anomalías CRÍTICAS: 756 títulos\n",
      "   • Anomalías ALTAS: 30,409 títulos\n",
      "   • Total prioritarios: 31,165 títulos (5.26%)\n",
      "\n",
      "🔍 ANÁLISIS POR COMPONENTE:\n",
      "   • Títulos con problemas de titulares: 7,013\n",
      "   • Títulos con discrepancias subterráneas: 27,530\n",
      "   • Títulos con discrepancias superficiales: 6,678\n",
      "   • Títulos con anomalías de volumen: 1,946\n",
      "\n",
      "📈 ESTADÍSTICAS DE SCORING:\n",
      "   • Score mínimo: 0.00\n",
      "   • Score máximo: 23.00\n",
      "   • Score promedio: 3.17\n",
      "   • Score mediana: 3.00\n",
      "\n",
      "💾 EXPORTANDO RESULTADOS...\n",
      "   ✓ df_anomalias_completo.csv exportado\n",
      "   ✓ titulos_prioritarios.csv exportado (31,165 registros)\n",
      "   ✓ top_100_anomalias.csv exportado\n",
      "   ✓ resumen_anomalias.csv exportado\n",
      "\n",
      "🎯 RECOMENDACIONES FINALES:\n",
      "   1. Priorizar revisión de 31,165 títulos críticos/altos\n",
      "   2. Implementar validaciones automáticas para discrepancias de volumen\n",
      "   3. Revisar metodología de captura para aguas subterráneas\n",
      "   4. Establecer alertas para títulos con score > 10\n",
      "   5. Auditar títulos con múltiples titulares conflictivos\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# REPORTE FINAL Y EXPORTACIÓN DE RESULTADOS\n",
    "\n",
    "def generar_reporte_final():\n",
    "    \"\"\"\n",
    "    Genera un reporte final completo del análisis de anomalías\n",
    "    \"\"\"\n",
    "    print(\"=\"*100)\n",
    "    print(\"                    REPORTE FINAL DE ANÁLISIS DE ANOMALÍAS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    print(\"\\nRESUMEN EJECUTIVO:\")\n",
    "    print(f\"   • Total de títulos analizados: {df_anomalias_final.height:,}\")\n",
    "    \n",
    "    # Distribución de anomalías\n",
    "    distribucion = df_anomalias_final.group_by('clasificacion_anomalia').agg([\n",
    "        pl.len().alias('cantidad'),\n",
    "        (pl.len() / df_anomalias_final.height * 100).alias('porcentaje')\n",
    "    ]).sort('cantidad', descending=True)\n",
    "    \n",
    "    print(f\"\\nDISTRIBUCIÓN DE ANOMALÍAS:\")\n",
    "    for row in distribucion.iter_rows(named=True):\n",
    "        print(f\"   • {row['clasificacion_anomalia']}: {row['cantidad']:,} títulos ({row['porcentaje']:.2f}%)\")\n",
    "    \n",
    "    # Títulos con anomalías críticas y altas\n",
    "    criticas = df_anomalias_final.filter(pl.col('clasificacion_anomalia') == 'CRÍTICA').height\n",
    "    altas = df_anomalias_final.filter(pl.col('clasificacion_anomalia') == 'ALTA').height\n",
    "\n",
    "    print(f\"\\n⚠️ TÍTULOS PRIORITARIOS:\")\n",
    "    print(f\"   • Anomalías CRÍTICAS: {criticas:,} títulos\")\n",
    "    print(f\"   • Anomalías ALTAS: {altas:,} títulos\")\n",
    "    print(f\"   • Total prioritarios: {criticas + altas:,} títulos ({(criticas + altas)/df_anomalias_final.height*100:.2f}%)\")\n",
    "    \n",
    "    # Análisis por componente de anomalía\n",
    "    print(f\"\\n🔍 ANÁLISIS POR COMPONENTE:\")\n",
    "    \n",
    "    # Anomalías de titulares\n",
    "    titulares_problematicos = df_anomalias_final.filter(pl.col('score_titulares') > 0).height\n",
    "    print(f\"   • Títulos con problemas de titulares: {titulares_problematicos:,}\")\n",
    "    \n",
    "    # Discrepancias subterráneas\n",
    "    disc_sub_count = df_anomalias_final.filter(\n",
    "        pl.col('discrepancias_subterraneas_count').is_not_null() & \n",
    "        (pl.col('discrepancias_subterraneas_count') > 0)\n",
    "    ).height\n",
    "    print(f\"   • Títulos con discrepancias subterráneas: {disc_sub_count:,}\")\n",
    "    \n",
    "    # Discrepancias superficiales\n",
    "    disc_sup_count = df_anomalias_final.filter(\n",
    "        pl.col('discrepancias_superficiales_count').is_not_null() & \n",
    "        (pl.col('discrepancias_superficiales_count') > 0)\n",
    "    ).height\n",
    "    print(f\"   • Títulos con discrepancias superficiales: {disc_sup_count:,}\")\n",
    "    \n",
    "    # Anomalías de volumen\n",
    "    vol_anomalias = df_anomalias_final.filter(pl.col('score_volumenes') > 0).height\n",
    "    print(f\"   • Títulos con anomalías de volumen: {vol_anomalias:,}\")\n",
    "    \n",
    "    print(f\"\\n📈 ESTADÍSTICAS DE SCORING:\")\n",
    "    stats_scoring = df_anomalias_final.select([\n",
    "        pl.col('score_anomalia_total').min().alias('score_min'),\n",
    "        pl.col('score_anomalia_total').max().alias('score_max'),\n",
    "        pl.col('score_anomalia_total').mean().alias('score_promedio'),\n",
    "        pl.col('score_anomalia_total').median().alias('score_mediana')\n",
    "    ])\n",
    "    \n",
    "    for row in stats_scoring.iter_rows(named=True):\n",
    "        print(f\"   • Score mínimo: {row['score_min']:.2f}\")\n",
    "        print(f\"   • Score máximo: {row['score_max']:.2f}\")\n",
    "        print(f\"   • Score promedio: {row['score_promedio']:.2f}\")\n",
    "        print(f\"   • Score mediana: {row['score_mediana']:.2f}\")\n",
    "    \n",
    "    return distribucion\n",
    "\n",
    "def exportar_resultados():\n",
    "    \"\"\"\n",
    "    Exporta los resultados a archivos CSV para análisis posterior\n",
    "    \"\"\"\n",
    "    print(f\"\\n💾 EXPORTANDO RESULTADOS...\")\n",
    "    \n",
    "    # Seleccionar solo columnas numéricas y de texto para exportación\n",
    "    columnas_exportables = [\n",
    "        'titulo', 'N_titulares', 'Score', 'Diferente_titular',\n",
    "        'Cambios_en_20_periodos', 'Cantidad_periodos',\n",
    "        'Anomalia_V_Total', 'Anomalia_V_Subterraneo', 'Anomalia_V_Superficial',\n",
    "        'discrepancias_subterraneas_count', 'discrepancia_subterranea_promedio',\n",
    "        'discrepancia_subterranea_maxima', 'discrepancia_subterranea_mediana',\n",
    "        'discrepancias_superficiales_count', 'discrepancia_superficial_promedio', \n",
    "        'discrepancia_superficial_maxima', 'discrepancia_superficial_mediana',\n",
    "        'total_registros_sub', 'registros_coincidentes_sub', 'porcentaje_consistencia_sub',\n",
    "        'total_registros_sup', 'registros_coincidentes_sup', 'porcentaje_consistencia_sup',\n",
    "        'score_titulares', 'score_discrepancias_sub', 'score_discrepancias_sup',\n",
    "        'score_volumenes', 'score_frecuencia_cambios', 'score_anomalia_total',\n",
    "        'clasificacion_anomalia'\n",
    "    ]\n",
    "    \n",
    "    # Crear dataframe para exportación\n",
    "    df_export = df_anomalias_final.select([col for col in columnas_exportables if col in df_anomalias_final.columns])\n",
    "    \n",
    "    # Exportar df_anomalias_final completo\n",
    "    df_export.write_csv(\"df_anomalias_completo.csv\")\n",
    "    print(f\"   ✓ df_anomalias_completo.csv exportado\")\n",
    "    \n",
    "    # Exportar solo títulos con anomalías críticas y altas\n",
    "    prioritarios = df_export.filter(\n",
    "        pl.col('clasificacion_anomalia').is_in(['CRÍTICA', 'ALTA'])\n",
    "    ).sort('score_anomalia_total', descending=True)\n",
    "    \n",
    "    prioritarios.write_csv(\"titulos_prioritarios.csv\")\n",
    "    print(f\"   ✓ titulos_prioritarios.csv exportado ({prioritarios.height:,} registros)\")\n",
    "    \n",
    "    # Exportar top 100 títulos con mayor score\n",
    "    top_100 = df_export.sort('score_anomalia_total', descending=True).head(100)\n",
    "    top_100.write_csv(\"top_100_anomalias.csv\")\n",
    "    print(f\"   ✓ top_100_anomalias.csv exportado\")\n",
    "    \n",
    "    # Resumen estadístico\n",
    "    resumen = df_anomalias_final.group_by('clasificacion_anomalia').agg([\n",
    "        pl.len().alias('cantidad'),\n",
    "        pl.col('score_anomalia_total').mean().alias('score_promedio'),\n",
    "        pl.col('score_anomalia_total').min().alias('score_min'),\n",
    "        pl.col('score_anomalia_total').max().alias('score_max'),\n",
    "        pl.col('N_titulares').mean().alias('titulares_promedio'),\n",
    "        pl.col('discrepancias_subterraneas_count').sum().alias('total_discrepancias_sub'),\n",
    "        pl.col('discrepancias_superficiales_count').sum().alias('total_discrepancias_sup')\n",
    "    ])\n",
    "    \n",
    "    resumen.write_csv(\"resumen_anomalias.csv\")\n",
    "    print(f\"   ✓ resumen_anomalias.csv exportado\")\n",
    "    \n",
    "    return prioritarios, top_100\n",
    "\n",
    "# Ejecutar reporte y exportación\n",
    "distribucion_final = generar_reporte_final()\n",
    "prioritarios, top_100 = exportar_resultados()\n",
    "\n",
    "print(f\"\\n🎯 RECOMENDACIONES FINALES:\")\n",
    "print(f\"   1. Priorizar revisión de {prioritarios.height:,} títulos críticos/altos\")\n",
    "print(f\"   2. Implementar validaciones automáticas para discrepancias de volumen\")\n",
    "print(f\"   3. Revisar metodología de captura para aguas subterráneas\")\n",
    "print(f\"   4. Establecer alertas para títulos con score > 10\")\n",
    "print(f\"   5. Auditar títulos con múltiples titulares conflictivos\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75f1c6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "                        EJEMPLOS DE TÍTULOS PROBLEMÁTICOS\n",
      "====================================================================================================\n",
      "\n",
      "🚨 TOP 5 TÍTULOS CON MAYOR SCORE DE ANOMALÍA:\n",
      "\n",
      "1. TÍTULO: 04PUE103357/18ASGE00\n",
      "   Score Total: 23.0 - CRÍTICA\n",
      "   Titulares: 1 | Conflictivos: None\n",
      "   Cambios en períodos: 20\n",
      "   Discrepancias subterráneas: 40 (consistencia: 0.0%)\n",
      "   Discrepancias superficiales: 40 (consistencia: 0.0%)\n",
      "\n",
      "2. TÍTULO: 6CHS100642/30APGE94\n",
      "   Score Total: 21.0 - CRÍTICA\n",
      "   Titulares: 2 | Conflictivos: 0\n",
      "   Cambios en períodos: 20\n",
      "   Discrepancias subterráneas: 60 (consistencia: 0.0%)\n",
      "\n",
      "3. TÍTULO: 11CHS103721/30HMOC07\n",
      "   Score Total: 21.0 - CRÍTICA\n",
      "   Titulares: 2 | Conflictivos: 0\n",
      "   Cambios en períodos: 20\n",
      "   Discrepancias subterráneas: 40 (consistencia: 0.0%)\n",
      "\n",
      "4. TÍTULO: 08GUA120364/12AMDL10\n",
      "   Score Total: 21.0 - CRÍTICA\n",
      "   Titulares: 2 | Conflictivos: 0\n",
      "   Cambios en períodos: 20\n",
      "   Discrepancias subterráneas: 56 (consistencia: 0.0%)\n",
      "\n",
      "5. TÍTULO: 12YUC110233/32IMGR00\n",
      "   Score Total: 21.0 - CRÍTICA\n",
      "   Titulares: 2 | Conflictivos: 0\n",
      "   Cambios en períodos: 20\n",
      "   Discrepancias subterráneas: 80 (consistencia: 0.0%)\n",
      "\n",
      "\n",
      "🔍 EJEMPLOS POR TIPO DE PROBLEMA:\n",
      "\n",
      "1. TÍTULOS CON MÚLTIPLES TITULARES CONFLICTIVOS:\n",
      "   • COL107120... | Titulares: 2 | Score: 13.0\n",
      "   • SON120487... | Titulares: 2 | Score: 10.0\n",
      "   • CHI101508... | Titulares: 2 | Score: 13.0\n",
      "\n",
      "2. TÍTULOS CON PEORES DISCREPANCIAS SUBTERRÁNEAS:\n",
      "   • GUA106928... | Consistencia: 0.0% | Score: 8.0\n",
      "   • 07ZAC117681/37AMDL17... | Consistencia: 0.0% | Score: 11.0\n",
      "   • 11TAB107444/30HSGE99... | Consistencia: 0.0% | Score: 11.0\n",
      "\n",
      "3. TÍTULOS CON PEORES DISCREPANCIAS SUPERFICIALES:\n",
      "   • 11TAB107443/30HSGE99... | Consistencia: 0.0% | Score: 19.0\n",
      "   • 11TAB107434/30HSGE99... | Consistencia: 0.0% | Score: 17.0\n",
      "   • MCH121661... | Consistencia: 0.0% | Score: 11.0\n",
      "\n",
      "4. TÍTULOS CON MÁS CAMBIOS DE VOLUMEN:\n",
      "   • 09TAM112795/25CHGR99... | Vol.Total: 6, Sub: 6, Sup: 1 | Score: 7.0\n",
      "   • 07DGO159221/36AMDA19... | Vol.Total: 6, Sub: 6, Sup: 1 | Score: 7.0\n",
      "   • 814967... | Vol.Total: 5, Sub: 5, Sup: 1 | Score: 6.0\n",
      "\n",
      "\n",
      "✅ ANÁLISIS COMPLETO FINALIZADO\n",
      "📁 Archivos exportados en el directorio actual:\n",
      "   • df_anomalias_completo.csv\n",
      "   • titulos_prioritarios.csv\n",
      "   • top_100_anomalias.csv\n",
      "   • resumen_anomalias.csv\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# EJEMPLOS DE TÍTULOS PROBLEMÁTICOS PARA VALIDACIÓN\n",
    "\n",
    "def mostrar_ejemplos_problematicos():\n",
    "    \"\"\"\n",
    "    Muestra ejemplos específicos de los títulos más problemáticos para validación manual\n",
    "    \"\"\"\n",
    "    print(\"=\"*100)\n",
    "    print(\"                        EJEMPLOS DE TÍTULOS PROBLEMÁTICOS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # TOP 5 títulos con score más alto\n",
    "    print(\"\\n🚨 TOP 5 TÍTULOS CON MAYOR SCORE DE ANOMALÍA:\")\n",
    "    top_5 = df_anomalias_final.sort('score_anomalia_total', descending=True).head(5)\n",
    "    \n",
    "    for i, row in enumerate(top_5.iter_rows(named=True), 1):\n",
    "        print(f\"\\n{i}. TÍTULO: {row['titulo']}\")\n",
    "        print(f\"   Score Total: {row['score_anomalia_total']:.1f} - {row['clasificacion_anomalia']}\")\n",
    "        print(f\"   Titulares: {row['N_titulares']} | Conflictivos: {row['Diferente_titular']}\")\n",
    "        print(f\"   Cambios en períodos: {row['Cambios_en_20_periodos']}\")\n",
    "        \n",
    "        if row['discrepancias_subterraneas_count'] and row['discrepancias_subterraneas_count'] > 0:\n",
    "            print(f\"   Discrepancias subterráneas: {row['discrepancias_subterraneas_count']} (consistencia: {row['porcentaje_consistencia_sub']:.1f}%)\")\n",
    "        if row['discrepancias_superficiales_count'] and row['discrepancias_superficiales_count'] > 0:\n",
    "            print(f\"   Discrepancias superficiales: {row['discrepancias_superficiales_count']} (consistencia: {row['porcentaje_consistencia_sup']:.1f}%)\")\n",
    "    \n",
    "    # Ejemplos por tipo de problema\n",
    "    print(f\"\\n\\n🔍 EJEMPLOS POR TIPO DE PROBLEMA:\")\n",
    "    \n",
    "    # Títulos con múltiples titulares conflictivos\n",
    "    print(f\"\\n1. TÍTULOS CON MÚLTIPLES TITULARES CONFLICTIVOS:\")\n",
    "    titulares_conflictivos = df_anomalias_final.filter(\n",
    "        (pl.col('N_titulares') > 1) & (pl.col('Diferente_titular') == 0)\n",
    "    ).sort('N_titulares', descending=True).head(3)\n",
    "    \n",
    "    for row in titulares_conflictivos.iter_rows(named=True):\n",
    "        print(f\"   • {row['titulo'][:50]}... | Titulares: {row['N_titulares']} | Score: {row['score_anomalia_total']:.1f}\")\n",
    "    \n",
    "    # Títulos con peores discrepancias subterráneas\n",
    "    print(f\"\\n2. TÍTULOS CON PEORES DISCREPANCIAS SUBTERRÁNEAS:\")\n",
    "    peores_sub = df_anomalias_final.filter(\n",
    "        pl.col('porcentaje_consistencia_sub').is_not_null()\n",
    "    ).sort('porcentaje_consistencia_sub').head(3)\n",
    "    \n",
    "    for row in peores_sub.iter_rows(named=True):\n",
    "        print(f\"   • {row['titulo'][:50]}... | Consistencia: {row['porcentaje_consistencia_sub']:.1f}% | Score: {row['score_anomalia_total']:.1f}\")\n",
    "    \n",
    "    # Títulos con peores discrepancias superficiales\n",
    "    print(f\"\\n3. TÍTULOS CON PEORES DISCREPANCIAS SUPERFICIALES:\")\n",
    "    peores_sup = df_anomalias_final.filter(\n",
    "        pl.col('porcentaje_consistencia_sup').is_not_null()\n",
    "    ).sort('porcentaje_consistencia_sup').head(3)\n",
    "    \n",
    "    for row in peores_sup.iter_rows(named=True):\n",
    "        print(f\"   • {row['titulo'][:50]}... | Consistencia: {row['porcentaje_consistencia_sup']:.1f}% | Score: {row['score_anomalia_total']:.1f}\")\n",
    "    \n",
    "    # Títulos con más cambios de volumen\n",
    "    print(f\"\\n4. TÍTULOS CON MÁS CAMBIOS DE VOLUMEN:\")\n",
    "    cambios_volumen = df_anomalias_final.filter(\n",
    "        pl.col('score_volumenes') > 0\n",
    "    ).sort(['Anomalia_V_Total', 'Anomalia_V_Subterraneo', 'Anomalia_V_Superficial'], descending=True).head(3)\n",
    "    \n",
    "    for row in cambios_volumen.iter_rows(named=True):\n",
    "        print(f\"   • {row['titulo'][:50]}... | Vol.Total: {row['Anomalia_V_Total']}, Sub: {row['Anomalia_V_Subterraneo']}, Sup: {row['Anomalia_V_Superficial']} | Score: {row['score_anomalia_total']:.1f}\")\n",
    "\n",
    "# Ejecutar análisis de ejemplos\n",
    "mostrar_ejemplos_problematicos()\n",
    "\n",
    "print(f\"\\n\\n✅ ANÁLISIS COMPLETO FINALIZADO\")\n",
    "print(f\"📁 Archivos exportados en el directorio actual:\")\n",
    "print(f\"   • df_anomalias_completo.csv\")\n",
    "print(f\"   • titulos_prioritarios.csv\") \n",
    "print(f\"   • top_100_anomalias.csv\")\n",
    "print(f\"   • resumen_anomalias.csv\")\n",
    "print(\"=\"*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IberoProject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
